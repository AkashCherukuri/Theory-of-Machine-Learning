\hspace{4mm} Let us review what we've done so far. We first came up with an algorithm to find an estimator which tries to minimize the true risk by assuming that the empirical risk is related to it. We then realised that this need not always be the case, and that \emph{Overfitting} can occur. Inorder to combat this problem we induced a bias in the system by restricting the Hypothesis Class to a finite set of functions, using some prior knowledge about the problem. 
\begin{quote}
   \textit{ However, is it not possible to have a learning algorithm which requires no prior knowledge, and can come up with an estimator for a binary label set with reasonable accuracy and a high enough probability? }
\end{quote}

\noindent This is the question which we wish to answer here. The \emph{No-Free-Lunch-Theorem} defined below states that such a learning algorithm is impossible for binary labelling. This means that some prior knowledge about the system is necessary to have a proper leaning algorithm, such as about the distribution $\mathcal{D}$ or whether the system satisfies the Realizability Assumption and the such.\\

\section{No Free Lunch Theorem}
\label{sec:nfl}

We shall state and prove the No Free Lunch Theorem, and understand why having a universal learner is not possible.
\begin{theorem}
(No Free Lunch) Let $A$ be a learning algorithm for the task of binary classification to the label set $\{0,1\}$ over the domain set $\mathcal{X}$. Let $m$ represent the size of training data, and $m<|\mathcal{X}/2|$. Then, for any distribution $D$ over the set $\mathcal{X}\times \{0,1\}$ we can state that:
\begin{enumerate}
    \item There exists a function $f$ such that $\mathcal{L}_D(f)=0$
    \item With a probability of at least 1/7 we have that $\mathcal{L}_D(A(S))>1/8$
\end{enumerate}
\end{theorem}

Therefore from this theorem we can clearly see that no ``One-Size-Fits-All" solution exists for our problem. Now we can establish \emph{why} prior knowledge is so important by using this theorem. Without any prior knowledge, we would have to consider the entire hypothesis set, $\mathcal{H}$, which would contain all the possible hypotheses. By contradiction, we can prove that no algorithm exists which can reliably output a predictor for such a case, i.e., this is not PAC Learnable.\\

This can proved by contradiction, assume that there existed an algorithm, $A$, with respect to which the problem is PAC Learnable. If we were to take some values of $\epsilon<1/7, \delta<1/8$, we can quite clearly see that the assumption breaks down. \emph{Therefore, to be able to reliably produce an estimator, prior information is mandatory.}

Now the problem boils down to choosing which Hypothesis class should be chosen, and how. On the one hand, we would be needed to have a class which either has the true estimator(which is unknown) with the realizability assumption, or if it doesn't, have the minimum value of the true error of the estimator to be low. On the other hand, if we were to try and increase the size of the Hypothesis Class, that would cause the decrease in the standards of the learning. We breakdown the error that is generated by the estimator to better understand the cause of this problem.

\section{Error Decomposition}
\label{sec:ed}

We know that the true error for an estimator $h$ is represented as $\mathcal{L}_D(h)$. We now decompose the error as follows:
$$
    \mathcal{L}_D(h) = \epsilon_{app} + \epsilon_{est} = \min\limits_{h'\in\mathcal{H}}\mathcal{L}_D(h') + \{\mathcal{L}_D(h) - \min\limits_{h'\in\mathcal{H}}\mathcal{L}_D(h')\}
$$

Here, $\epsilon_{app}$ stands for the \emph{Approximation Error}, and $\epsilon_{est}$ stands for the \emph{Estimation Error}. We shall look at what each of them represents subsequently.\\

\begin{enumerate}
    \item \emph{Approximation Error} quantifies the amount of error that is obtained by approximating that the estimator belongs to the estimator class. In other words, it quantifies the amount of inductive bias that has been introduced in the system. Under the realizability assumption, we can see that the approximation error is zero. \emph{Also note that Bayes' Estimator gives a lower bound for what the approximation error can be.}
    
    \item \emph{Estimation Error} results because the emperical risk is only an estimate of what the true risk is, and it might be misleading as well. As we've seen already, \emph{Estimation error increases logarithmically with $|\mathcal{H}|$ and decreases with $m$.} That is, this error is dependant on the complexity of the sample.
\end{enumerate}
\vspace{5mm}
\hspace{6mm}We strive to minimize both the errors as much as possible, but we can see that they are related in polar opposite manners to the size of the Hypothesis Class. Thus, we enter a trade-off, which is called as the \emph{Bias-Complexity Tradeoff}. Causing the estimator class to be rich causes overfitting, wheras having a small hypothesis class causes underfitting. Most of empirical research strives on obtaining the perfect estimator class that excels in minimizing both to the maximum possible extent.\\

However, all this analysis has been done assuming that the hypothesis class, $\mathcal{H}$, is finite. Let us now shift our goals towards the analysis of PAC Learnability when the hypothesis class is infinite in size. Surely, there must be some characteristics common to all the infinite classes, and that is what we wish to uncover.\\

\section{VC Dimensions}
\label{sec:infH}

In order to show that infinite hypothesis classes do exist, we first give an example of such a class, and prove that it is in fact PAC Learnable.\\

\begin{example}
Define a hypothesis class, $\mathcal{H}$ as; 
$$\mathcal{H} = \{ h_a : \forall a \in \mathbb{R} \}\text{ where }
    h_a(x) = 
    \begin{dcases}
        1, &x>a\\
        0, &\text{otherwise}\\
    \end{dcases}
$$

Clearly the hypothesis class is infinite. To prove that this is PAC learnable, with a sample complexity of $m_\mathcal{H}\leq \left[ \frac{\log(2/\delta)}{\epsilon} \right]$, we first label the true value of $a$ as $a_t$, such that $\mathcal{L}_D(h_{a_t})=0$. Now assume that probability of the error which we can allow in the measurement of $a_t$ is $\epsilon$. That means;
$$
    \exists (a_o, a_1)\in\mathbb{R}^2 \text{ such that } \text{P}[x\in(a_o,a_t)] = \text{P}[x\in(a_t,a_1)] = \epsilon 
$$

Let the sample-label set be $S$, which is obviously finite. Ideally, we know that all the values of $\{x,1\}\in S$ would have $x<a_t$, and the rest would be $\{x,0\},\text{ }x>a_t$. Therefore, for our estimator to be able to give a value in between $(a_o,a_1)$, we can see that;
$$
    \max\limits_{\{x,1\}\in S}(x)>a_o \text{ AND } \min\limits_{\{x,0\}\in S}(x)<a_1
$$

For simplicity, we shall represent $\max\limits_{\{x,1\}\in S}(x) \text{ as } b_o\text{ and }\min\limits_{\{x,0\}\in S}(x)\text{ as }b_1$. Let the parameter that is obtained by the ERM estimator be $a_{ERM}$. We can see that $a_{ERM}\in (b_o,b_1)$. Therefore, the condition mentioned above is \emph{SUFFICIENT} for the learning to be successful. This implies;
\begin{align*}
    \text{P}[\mathcal{L}_D(h_{ERM})<\epsilon] &\geq \text{P}[b_o>a_o \wedge b_1<a_1]\\
    \text{P}[\mathcal{L}_D(h_{ERM})>\epsilon] &\leq \text{P}[b_o<a_o \lor b_1>a_1]\\
    &\leq \text{P}[b_o<a_o]+\text{P}[b_1>a_1]\\
    &\leq \frac{\delta}{2} + \frac{\delta}{2} \qquad \text{(Using sample complexity)}\\
    &\leq \delta
\end{align*}
Therefore, the hypothesis class is PAC Learnable as shown using the ERM hypothesis.
\end{example}

Therefore, we have seen that finiteness of a hypothesis class is a sufficient condition for learnability, and it is not necessary. We shall now use the definition of VC Dimensions to create a classification which would enable us to differentiate which classes are learnable and which are not.\\
